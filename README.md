# Vibez 
## The app that genreates a playlist to match the vibe
Application by Megan Hazlett   
Lead QA Amanda Infeld 

## Project Charter 	

**Vision:** “What’s the vibe?” By answering just one question, music lovers will be able to access curated playlists based on the mood of the room. While there are several existing applications which allow music listeners to create playlists by adding songs one by one, Vibez will help users save time by providing complete playlists for any occasion. 	

**Mission:** The app will have simple design and will prompt users to select an answer to the question, “What’s the vibe?” The model will then recommend a list of songs curated from K-means clustering on music features using the dataset [https://data.world/kcmillersean/billboard-hot-100-1958-2017]. The songs on the dataset come from Billboard Hot 100 charts since 1958, which will provide novelty and familiarity in the playlists curated by the app. Our hopes is that our users will find the app fun and handy!	

**Success Criteria:**	
*Machine Learning Criteria:* The metrics used to evaluate the success of the K-means model will be the sum of squares within (SSW) and elbow plots. We want the SSW to be small to indicate homogeneity of the music selected for each playlist. We will use the elbow plots to determine the ideal number of clusters. 
	
*Business Success Criteria:* The app will be considered a success from a business standpoint if 50 percent of first-time users return to the app and if 130,000 new users, 1 percent of Spotify’s active users, download this app. 	

# Directory Structure 
```
├── README.md                         <- You are here
├── app/
│   ├── boot.sh				<- Used by Docker to build the app 
│   ├── Dockerfile			<-Dockerfile to build the app 
│   ├── static/				<- Folder holds CSS information
│   ├── tempates/			<-Folder holds html files for app 
│   		├── error.html		<-Html for app error page
│   		├── index.html		<-Html for app home page 	
│   		├── results.html	<-Html for app recommendations page		
├── config/
│   ├── flaskconfig,py			<- Configurations for flask app
│   ├── logging/			<- Configuration of python loggers 
│
├── data/				<- Contains all output generated by scripts 
│   ├── model_results/			<- Data obtained from models.py
│   ├── test/				<- Folder where testing data is placed
│   		├── models_results/	<-Data to be tested by models and data obtained from testing models.py		
│
├── src/				<- Source python files for the project 
│   ├── acquire_data.py			<- Used to acquire data from S3 bucket 
│   ├── data_to_s3.py			<- Used to send data to S3 bucket
│   ├── config.yml			<- Yaml file to be configured by user for file placement; It is recommended that the user keep defaults for smooth performance
│   ├── cofigure_db.py			<- Sets up a database locally or in RDS
│   ├── models.py			<- Cleans the data, trains the k-means model, and generates cluster labels
│   ├── test_config.py			<- Yaml file to be configure by the user for file placement of test items; It is recommended that the user keep defaults for smooth performance
│   ├── test_models.py			<- Unit tests for function in models.py
│
├── app.py			 	<- Code to build flask app 
│
├── Dockerfile			 	<- Creates image of pipeline
│
├── run_pipeline.sh 			 <- Used by Dockerfile to run entire pipeline
│
├── requirements.txt 			 <- Python package dependencies 
│
├── myconfig.env 			 <- User specific environment variables to be entered here
│
├── run_mysql_client.sh 		 <- Extra file to run the sql client for RDS
```

# Instructions for Running Model Pipeline
Please clone this repo (2020-msia420-hazlett-vibez) to your local computer and cd into it

## About the Model Pipeline
This pipeline will acquire the data from S3 bucket, clean it, train the model, evaluate the model, deploy the model, run unit tests on the model and load it into a local database. 

## Directory Specifications 
Make sure that you are in the directory 2020-msia423-hazlett-vibez prior to building the Docker image 

## Option 1: Using myconfig.env file

### Setting Up Environment Variables 
Edit the myconfig.env file with the following information 

```bash
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
MYSQL_USER=
MYSQL_PASSWORD=
MYSQL_HOST=
MYSQL_PORT=
MYSQL_DB=vibez_db
```

### Build the image 

`docker build -f Dockerfile -t vibez .`

### Execute the pipeline
`docker run --env-file=myconfig.env --mount type=bind,source="$(pwd)"/data,target=/app/data vibez run_pipeline.sh`

## Option 2: Using environment variables 

### Export environment variables 

```bash
export AWS_ACCESS_KEY_ID=AKIAJIGPWF37T7RHJOLQ
export AWS_SECRET_ACCESS_KEY=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
```
### Build the image 

`docker build -f Dockerfile -f vibes .`

### Execute the pipeline
`docker run -e AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY --mount type=bind,source="$(pwd)"/data,target=/app/data vibez run_pipeline.sh`


## Note: If you want to load into a RDS database ...
Connect to the Northwestern VPN and replace the line reading 

`python3 src/configure_db.py`

in run_pipeline.py with 

`python3 src/configure_db.py --rds rds`


# Instructions for Launching the App 

## Option 1: Using Local Database 
### Directory Specifications 
Make sure that you are in the directory 2020-msia423-hazlett-vibez

### Build the image 
`docker build -f app/Dockerfile -t vibezapp . `

### Execute the pipeline 
`docker run  -p 5000:5000 --name test vibezapp`

### View the App
You should now be able to access the app at [http://0.0.0.0:5000/](http://0.0.0.0:5000/) in your browser.

### Make sure to run the following when you are finished with the app, open a new terminal and type
`docker kill test`

## Option 2: Using RDS 
### Directory Specifications 
Make sure that you are in the directory 2020-msia423-hazlett-vibez and connected to the Northwestern VPN prior to building the Docker image 

### Build the image 

`docker build -f app/Dockerfile -t vibezapp . `

### Option 2.1: Execute the pipeline using myconfig.env file
`docker run --env-file=myconfig.env -p 5000:5000 --name test vibezapp`

### Option 2.2: Execute the pipeline using SQLALCHEMY_DATABASE_URI
`export SQLALCHEMY_DATABASE_URI=`

`docker run -e SQLALCHEMY_DATABASE_URI -p 5000:5000 --name test vibezapp`

### View the App
You should now be able to access the app at [http://0.0.0.0:5000/](http://0.0.0.0:5000/) in your browser.

### Make sure to run the following when you are finished with the app, open a new terminal and type
`docker kill test`


# Extra Information

### About the Data 
The data for this project was obtained through [https://data.world/kcmillersean/billboard-hot-100-1958-2017/workspace/file?filename=Hot+100+Audio+Features.xls](https://data.world/kcmillersean/billboard-hot-100-1958-2017/workspace/file?filename=Hot+100+Audio+Features.xlsx). 
For this pipeline, the data has been placed in an s3 bucket and will be obtained in a model pipeline. 

### Loading Data to Your S3 Bucket
If you would like to place the data in your own S3 bucket after downloading from the website or running the model pipeline, you can specify location in src/config.yml and run the following commands. 

`docker build -f Dockerfile -t vibez .`

`docker run --env-file=myconfig.env --mount type=bind,source="$(pwd)"/data,target=/app/data vibez src/data_to_s3.py`


### To View RDS databse 
Cd into the repo
`cd 2020-msia4230hazlett-vibez`

Edit the file named .mysqlconfig and add in your information.
```bash
export MYSQL_USER=admin
export MYSQL_PASSWORD=
export MYSQL_HOST=
export MYSQL_PORT=
export DATABASE_NAME =
```
`source .mysqlconfig`

`source run_mysql_client.sh`

You can go in and look at the vibez_db with the following commands

`USE vibez_db;`

`SHOW TABLES;`


# Planning 	
**Initiative 1:** Model Building 	
* Epic 1: Data cleaning and exploratory data analysis 	
	* Story 1: Understand the data dictionary and determine which features would be interesting for the model 	
		* Data Details Page[https://data.world/kcmillersean/billboard-hot-100-1958-2017] 	
		* Billboard Dictionary[https://www.billboard.com/]	
		* Spotify API Dictionary [https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/]	
* Epic 2: Development and testing of K-means model for creating playlist clusters	
	* Story 1: Explore different feature combinations, number of iterations, and number of clusters to create ideal clusters on data. Use elbow plots to evaluate. 	
	* Story 2: Evaluate models using SSW	
	* Story 3: Check model stability by running K-means with different starting seeds	
 	* Story 4: Name the clusters from the best model 	
	* Story 5: Randomly draw m songs from each large cluster when prompted by the user to create a playlist	

**Initiative 2:** Create Application Front and Back Ends	
* Epic 1: Construct relational database 	
* Epic 2: Design and build user interface 	
	* Story 1: Create initial page of app	
	* Story 2: Design user input layout 	
	* Story 3: Create playlist results page	
* Epic 3: Use S3 to store raw data on AWS	
* Epic 4: Flask App Development	

**Initiative 3:** Test and deploy different iterations of the app to inform app development 	
* Epic 1: Deploy the best model	
* Epic 2: Build unit tests to evaluate functionality 	
* Epic 3: Design and conduct A/B tests to evaluate application versions 	





